----PROJECT NOTES----

21/02/2013

First entry so going to sum up everything so far...

Implemented an Adaptation of the GPU Marching cubes algorithm found in GPU gems. Discarded the bit about random generation and used reference tables originally from Eric Lengyel's Transvoxel Algorithm.

Disabled the GPU conversion for now, however, as it is a pain to maintain as I adapt the algorithm for better intergration with the physics side of the project. Will come back to it during the optimization phase.

CPU version of the algorithm is used instead. Not noticably slower, but then again I'm only converting 3 or 4 objects.

Voxel Conversion is working well, however normals always F*** up for some reason.

Bullet Physics is somewhat intergrated, it can only handle convex shapes but the rigid bodies sync up to their visual representations and behave pretty much as expected. For GPU processing mode, must keep in mind that I need to pull data back off the GPU so keep an eye on that performance hit.

Need to think of a solution to the following issues:

> Creating MatterNodes of Arbitrary Size. For GPU processing to remain viable they will have to be chunked, probably stick with the 32x32x32 blocks. CPU is less limited but may be an idea to chunk it anyway.
> Decomposing the Matter into convex shapes so they can be convertex to valid rigid bodies.
> Start testing algorithms for the breaking etc.

06/03/2013

Just spent many hours trying to get convex decomposition to work using the HACD library to process the vertices output from MC. Unfortunatly the lib performs a bit too slowly and tends to eventually kill itself with memory errors if I put too many in. I am instead going to attempt to implement my own algorithm that takes advantage of the fact that I know we are dealing with voxels. It will hopefully work as follows:

	1. Each voxel field also has a (seperate, possibly) 3d array that shows which sub-shape the shape belongs too. If the shape is convex this is all consistent.
	2. I use something like a flood fill algorithm in 3d to find the convex hulls within the voxel field.
	3. When processing the field with MC I also check the hull id and associate this with the vertex/triangle/whatever.
	4. When building rigid bodies I seperate the vertices into seperate hulls using the hull id.
	
08/03/2013

Have devised an Algorithm that SHOULD decompose the shapes at the voxel level. I need to now come up with a way of linking that with the vertices genereated by marching cubes.

Two options present themselves:
	1. Approximate the location of the vertices.
	
	So, as a 2D example
	
		1 ------ 1
		|        |
		|        |
        |		 |
		2 ------ 0
		
	Where 1 and 2 are hulls and 0 is empty, would generate one vertex between each conflicting edge, and one on each voxel:
	
		1 ------ 1
		|        |
		x    x   |
        |		 |
		2 ------ 0
		
	And both hulls that formed the vertice get a copy.
	
		x ---- x
		|  1  /   
		|    /
		x---x
         2 /
		  /
		x 
	
	2. During the MC algorithm, check the closest vertice to each edges vertices. If they differ, stick a new vertice in the middle and use that in both hulls.
	
1. is less precise, but I think it is close enough, while 2. seems a bit "too" precise.

One thing to consider, whichever I choose is that only cubes generated near edges (IE at least one empty corner) need to have hull vertices.

12/03/2013

Basic version of the above "fill" based algortihm implemented. It works by using "blocks" which can be thought of as cubes with knowledge about their neighbours. This allows them to expand in a way in which they will hopefully never create a convex shape. Currently the alogrithm works with some shapes, but it needs enhancements to make it more precise and robust. It can almost handle a donut shape, and the hulls generated are accurate enough for another shape to pass through if it is of a reasonable size. Currently I am just feeding the raw "voxel posistions" in as the hull points. What I should do is improve the consistency with MC is to displace each point based on that cubes "normal".
Okay, implemented that and seems to work pretty okay. The estimated hulls match the real ones perfectly on horizontal or vertical surfaces, though they slightly overestimate the distance on diagonals. Currently working on collision detection callbacks, will attempt to create a simple system where objects self delete if they hit something too hard. This will allow me to test how dynamically removing stuff from bullet works.

14/02/2013

Can get collision forces back from bullet now, though it's hard to tell if the numbers are genuine forces or what...

Either way, I need to move on to the actual destruction and deformation stuff soon. I currently believe there are two alternative ways in which I can build an internal physics model using the voxels:

	Option 1, the easy way.
	Completly invent my own way of calculating which voxels obliterate or where snapping occurs. I think a solution that uses the vector between two opposing forces and measures the strength of the structure along this line to determine if it snaps could work well. With possibly what I call the cone of anhilation and cone of displacment around each force allowing parts of the shape to be broken or disintigrated. Different materials would have different values that effect how much force is requried for each, so chalk will obliterate or shatter easily but won't dent or crack much first, while steel will pretty much always dent or occasionally snap, but will rarely dintigrate or crumble.

	Option 2, the smart way.
	Implement some kind of Mass-Spring model type thing. I'm not quite sure how to implement this myself though as it requires formulas for each voxel that depend on the neighbours, so how do you resolve that dependancy?

08/04/2013

I think I have come up with an algorithm that should work well.

Basically it assigns each voxel a certain amount of kinetic energy based on velocity IE each voxel has density * velocity KE. The voxels of the two colliding shapes then swap energy until every voxel has equal energy or until transfer is no longer possible due to breakages or such.

As energy is transferred in and out of a voxel it is subject to more and more stress and pressure. When a voxel undergoes too much pressure it obliterates into powder and basically vanishes, this also destroys some kinetic energy. When a voxel undergoes too much stress the same thing may occur, however this will only have a permenant effect if enough voxels break to create a continuous break line.

Once transfer is complete the velocities of the new matter chunks are calculated based on the amount of energy within their voxels.

Energy transfer consists of two phases: Direct, and Deferred. Direct transfer occurs in the direction of the collision force and only creates pressure, any energy that "falls off" the edge of the matter is then used in phase two. Direct transfer essentially only occurs in rough cylinder shapes from the contact points.

Perpendicular Transfer occurs in all remaing voxels that do not currently have the required amount of energy. This phase requires the creation of a "transfer map" that shows where each voxel will get it's energy from. The transfer map will link every non-energised voxel with at least one energised voxel. Once the transfer map is complete energy will flow from energised voxels to non energised voxels, creating stress and pressure along the way. The result of this is that voxels that act a bridges to large un-energised masses will undergoe the most stress and breaks may occur their.

20/4/2013

I have implemented the above alogrithms on the CPU side. However, they run incredibly slowly, dozens of seconds per collision.
I can aproximate that each direct transfer pass requires the processing of about 50% of the previous passes voxels with the optimisations I have made so far.
Despite those optimisations, the fact remains that processing potentially 32x32x32 = 32,768 voxels takes some time.
I have two options:
1) Try to optimize the shit out of the actual processing sub function.
2) Run the algorithm on the GPU instead.

Running the algorithm on the GPU could work with some optimizations, namely using two voxel buffers instead of one. Each "vertex" put into the GPU only needs to know it's coordinate and can them process some of the first buffer and output the changes into the second. After each pass, the buffers can be swapped. This does mean, however that more passes will be needed. As the current CPU algortihm runs through the voxels sequentially in the same direction as energy flow. Second voxel will have access to the energy it recieved from the first one, and therefore won't need an extra pass, and so on.

OLD CODE

while(oldSize != newSize) //End if no new voxels are added to graph.
    {
        oldSize = newSize;
        endOfStep = newSize;

        //Add adjanct nodes to map.
        for(unsigned int i = startOfStep; i < endOfStep; i++)
        {
            TransferNode currentNode = mTransferGraph[i];
            const Vector3i coord = currentNode.mVoxelCoord;

            //Get coords of adjanct nodes
            for(unsigned int k = 0; k < 26; k++)
            {
                Vector3i adjanctCoord = coord + getDirectionVector(k);
                if(validCoord(adjanctCoord))
                {
                    int nodeIndex = mTransferMap[adjanctCoord.x][adjanctCoord.y][adjanctCoord.z];

                    //Node has already been added to graph, but is "younger" than this node.
                    if(nodeIndex >= 0 && nodeIndex > endOfStep)
                    {
                        TransferNode& adjanctNode = mTransferGraph[nodeIndex];
                        char previousFeederDirection = getReverseDirection(adjanctNode.mFeederDirection)
                        float previousFeederStress = 1.0f - fabs(mCurrentMap[previousFeederDirection]);
                        float stress = 1.0f - fabs(mCurrentMap[k]);
                        
                        if(stress > previousFeederStress)
                        {
                            adjanctNode.mFeeder = i;
                            adjanctNode .
                        }
                        adjanctNode.mFeeders.push_back(i);
                        adjanctNode.mFeederDirections.push_back(getReverseDirection(k));
                    }
                    else if(nodeIndex < 0)
                    {
                        //Node has not been added, must check it is full.
                        VoxelData& voxel = mVoxelData[adjanctCoord.x][adjanctCoord.y][adjanctCoord.z];
                        if(voxel.mFull && !(voxel.mDestroyed || voxel.mSnapped))
                        {
                            mTransferGraph.push_back(TransferNode(false, adjanctCoord));
                            mTransferMap[adjanctCoord.x][adjanctCoord.y][adjanctCoord.z] = mTransferGraph.size()-1;
                            TransferNode& newNode = mTransferGraph.back();
                            newNode.mFeeders.push_back(i);
                            newNode.mFeederDirections.push_back(getReverseDirection(k));
                            newNode.mGeneration = generation;
                        }
                    }
                }
            }
        }

        newSize = mTransferGraph.size();
        startOfStep = endOfStep;
        generation++;
    }


}

27/04/2013

Had an idea to speed up the direct transfer algortihm. Just do something similar to external transfer where it's more a beam than a iterated thing.

Going to start, here is old code:

//MANDATORY OPTIMISATION:
    //Start at back of shape and work forward, as this may result in energy transfer in a single pass.

    int zStart = 0;
    int zEnd = 31;
    int zDirection = 1;

    int yStart = 0;
    int yEnd = 31;
    int yDirection = 1;

    int xStart = 0;
    int xEnd = 31;
    int xDirection = 1;

    if(mEnergyVectorLocal.x < 0)
    {
        xStart = 31;
        xEnd = 0;
        xDirection = -1;
    }
    if(mEnergyVectorLocal.y < 0)
    {
        yStart = 31;
        yEnd = 0;
        yDirection = -1;
    }
    if(mEnergyVectorLocal.z < 0)
    {
        zStart = 31;
        zEnd = 0;
        zDirection = -1;
    }

    //Create two lists of voxels, swap between them each pass.
    std::vector<Vector3i> voxelListA;
    std::vector<Vector3i> voxelListB;
    std::vector<Vector3i>* currentList = &voxelListA;
    std::vector<Vector3i>* otherList = &voxelListB;
    bool listIsA = true;

    std::cout << "    Building Initial List..." << std::endl;
    for(int z = zStart; z != zEnd; z += zDirection)
    {
        for(int y = yStart; y != yEnd; y += yDirection)
        {
            for(int x = xStart; x != xEnd; x += xDirection)
            {
                if(mVoxelData[x][y][z].mFull)
                {
                    //Already done else where
                    //mVoxelData[x][y][z].addEnergy(mIsReciever, startingEnergyPerVoxel);
                    currentList->push_back(Vector3i(x, y, z));
                }
            }
        }
    }


    while(currentList->size() > 0)
    {
        std::cout << "    Transfer Step..." << std::endl;
        //Transfer energy from all voxels.
        for(unsigned int i = 0; i < currentList->size(); i++)
        {
            directTransferVoxel(currentList->at(i));
        }
        std::cout << "    Rebuilding List..." << std::endl;
        //Check if energy can be transferred again.
        for(unsigned int i = 0; i < currentList->size(); i++)
        {
            Vector3i coord = currentList->at(i);
            VoxelData& voxel = mVoxelData[coord.x][coord.y][coord.z];
            if(voxel.getEnergy(mIsReciever) > mEnergyPerVoxel)
            {
                otherList->push_back(coord);
            }
        }
        //Swap lists
        std::vector<Vector3i>* temp = currentList;
        currentList = otherList;
        otherList = temp;
        otherList->clear();
    }
	
28/04/2013
	
Pressure still creates a bit too much of a "blocky" effect on collison. I want to to be more of a cone, can't spend too long thinking though so just move on. Need to test stress is working well now.

2/05/2013

Deadline Approaching! OMG BAILOUT! Nah, just kidding. Shit to do before 10th, in order of importance:

	- Fix circle jerk bug when many different objects collide. (dunno)
	- Inherit momentum from parent object(s). (easy-ish)
	- Optimize so it isn't shit. (hard?)
		- Including Reimplement GPU stuff, with Convex Decomp integrated.
	- Add debugging tools. (hard.)
	

3/05/2013

No longer circle-jerks. Need to add some kind of filter after direct transfer... or just make it much more efficent in general.

Current Bottlenecks: 
	Indirect Transfer <- Find which parts
	Generating new Matter Nodes. <- Find if MC or Convex Decomp or both.

Okay. When there is a lot of energy to move around, transfer time in indirect transfer is about .25 seconds, but overwise pretty negiligle. Graph building usually takes about .05 depending on how the collision goes. Both of them seem pretty slow.

When generating, MC is the bottleneck. GPU acceleration would probably help a lot.

My new idea for indirect transfer:

	Nodes in the direct transfer paths are immune.
	For each of those nodes, 

Can't figure out a way to work it.

Try to optimize what we have now real quick...
Here is old code for graph building:

void EnergyGrid::buildTransferGraph()
{
    mTransferGraph.clear();

    unsigned int startOfStep = 0;
    unsigned int endOfStep = 0;

    //Reset the transfermap
    mTransferMap = std::vector<std::vector<std::vector<int>>>(32, std::vector<std::vector<int>>(32, std::vector<int>(32, -1)));

    //Add source voxels to graph
    for(unsigned int x = 0; x < 32; x++)
    {
        for(unsigned int y = 0; y < 32; y++)
        {
            for(unsigned int z = 0; z < 32; z++)
            {
                VoxelData& voxel = mVoxelData[x][y][z];
                if(//voxel.mFull && !voxel.mDestroyed &&
                   voxel.getEnergy(mIsReciever) >= mEnergyPerVoxel)
                {
                    mTransferGraph.push_back(TransferNode(true, Vector3i(x, y, z)));
                    mTransferGraph.back().mGeneration = 0;
                    mTransferMap[x][y][z] = mTransferGraph.size()-1;
                    endOfStep++;
                }
            }
        }
    }

    unsigned int oldSize = 0;
    unsigned int newSize = endOfStep;

    unsigned int generation = 1;

    //Expand graph
    while(oldSize != newSize) //End if no new voxels are added to graph.
    {
        oldSize = newSize;
        endOfStep = newSize;

        //Add adjanct nodes to map.
        for(unsigned int i = startOfStep; i < endOfStep; i++)
        {
            TransferNode currentNode = mTransferGraph[i];
            const Vector3i coord = currentNode.mVoxelCoord;

            //Get coords of adjanct nodes
            for(unsigned int k = 0; k < 27; k++)
            {
                Vector3i adjanctCoord = coord + getDirectionVector(k);
                if(validCoord(adjanctCoord))
                {
                    int nodeIndex = mTransferMap[adjanctCoord.x][adjanctCoord.y][adjanctCoord.z];

                    //Node has already been added to graph,
                     but is "younger" than this node.
                    if(nodeIndex >= 0 && nodeIndex > endOfStep)
                    {
                        TransferNode& adjanctNode = mTransferGraph[nodeIndex];
                        eDirection previousFeederDirection = getReverseDirection(adjanctNode.mFeederDirection);
                        float previousFeederStress = 1.0f - fabs(mCurrentMap[previousFeederDirection]);
                        float stress = 1.0f - fabs(mCurrentMap[k]);

                        //If this voxel is a better feeder, then use it instead of the previous one.
                        if(stress > previousFeederStress)
                        {
                            adjanctNode.mFeeder = i;
                            adjanctNode.mFeederDirection = getReverseDirection(k);
                        }
                    }
                    else if(nodeIndex < 0)
                    {
                        //Node has not been added, must check it is full.
                        VoxelData& voxel = mVoxelData[adjanctCoord.x][adjanctCoord.y][adjanctCoord.z];
                        if(voxel.mFull && !(voxel.mDestroyed || voxel.mSnapped))
                        {
                            mTransferGraph.push_back(TransferNode(false, adjanctCoord));
                            mTransferMap[adjanctCoord.x][adjanctCoord.y][adjanctCoord.z] = mTransferGraph.size()-1;
                            TransferNode& newNode = mTransferGraph.back();
                            newNode.mFeeder = i;
                            newNode.mFeederDirection = getReverseDirection(k);
                            newNode.mGeneration = generation;
                        }
                    }
                }
            }
        }

        newSize = mTransferGraph.size();
        startOfStep = endOfStep;
        generation++;
    }


}

What I did was build stress at the same time as the graph, then do a quick pass and apply it all at once. 
It seemed to result in much greater speed. 0.05 - 0.07 to build the graph which is *slightly* higher. 
However, time to transfer was cut down to 0.001 - 0.003 ish.
So worth it.

Actual destruction seems fast *enough* now. It really just slows down when collision sets get to about: 20 or so simulatneous "non trivial" collisions.
Also breaking, that is, the process of detecting breaks, takes about 0.5s. In some cases, so that obviously needs fixing.